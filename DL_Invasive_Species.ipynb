{
  "cells": [
    {
      "metadata": {
        "_uuid": "e413413c36009693fed5618b57a93f1cd883ca88"
      },
      "cell_type": "markdown",
      "source": "**Objective:** Trained scientists visit designated areas and take note of the species inhabiting them. Using such a highly qualified workforce is expensive, time inefficient, and insufficient since humans cannot cover large areas when sampling. Use DL to predict the presence or absence of invasive species in areas that have not been sampled."
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Get automatic reloading and inline plotting\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "### Import Required Libraries\n# Using Fastai Libraries\nfrom fastai.imports import *\nfrom fastai.transforms import *\nfrom fastai.conv_learner import *\nfrom fastai.model import *\nfrom fastai.dataset import *\nfrom fastai.sgdr import *\nfrom fastai.plots import *\nimport numpy as np\nimport pandas as pd\nimport torch",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c166af763d33dd4bb56095401ac29fffa4292465"
      },
      "cell_type": "markdown",
      "source": "PATH is the path to your data, and sz is the size that the images will be resized to in order to ensure that the training runs quickly.  bs is the batch size that is we can break the data up into smaller parts. arch, is the selected architecture of the neural network model."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d8f7701d190a601c666e1318a6605e8b5b577a9d"
      },
      "cell_type": "code",
      "source": "import os\nPATH = \"../input\"\nprint(os.listdir(PATH))\nTMP_PATH = \"/tmp/tmp\"\nMODEL_PATH = \"/tmp/model/\"\nsz= 224\nbs = 58\narch = resnet34",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2a3de878d4fc7b5d391a5b7ce6fd6ec66458404c"
      },
      "cell_type": "markdown",
      "source": "The programming framework used to behind the scenes to work with NVidia GPUs is called CUDA. Further, to improve performance, we need to check for NVidia package called CuDNN (special accelerated functions for deep learning)."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d9b3d5c37a7be5be79876d41f6cd89df4d13935"
      },
      "cell_type": "code",
      "source": "### Checking GPU Set up\nprint(torch.cuda.is_available())\nprint(torch.backends.cudnn.enabled)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f68653ac5c9f1eeab0741f3bd581ba41fede0c45"
      },
      "cell_type": "code",
      "source": "files = os.listdir(f'{PATH}/train')[:5]\nfiles",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6fdd00f7bebe936477bb72cc344f44b3f3f9dd61"
      },
      "cell_type": "markdown",
      "source": "Let's explore what the data images look like:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8637a21c098109db663b71cb7938af50532038d7"
      },
      "cell_type": "code",
      "source": "img = plt.imread(f'{PATH}/train/{files[0]}')\nplt.imshow(img);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "45ffbec6881a1e1554bd1eda0cf3b63026c3c65b"
      },
      "cell_type": "code",
      "source": "img.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e8c6f474fae4827b7d227a6a12b2516605a8eb43"
      },
      "cell_type": "code",
      "source": "img[:4,:4]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a090980819f4ac03ed962f622ed7aa7fae9e2ad8"
      },
      "cell_type": "markdown",
      "source": "Get the distribution of the image sizes:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "69f95c932883b7617f82b74737f66307dacb7603"
      },
      "cell_type": "code",
      "source": "label_csv = f'{PATH}/train_labels.csv'\nn = len(list(open(label_csv))) - 1 # header is not counted (-1)\nval_idxs = get_cv_idxs(n) # random 20% data for validation set\nprint(n)\nprint(len(val_idxs))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "69e7bc1076ead77da458b01937c8146103d4f16a"
      },
      "cell_type": "code",
      "source": "label_df = pd.read_csv(label_csv)\nlabel_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6c1d36efd2f9daa9eacbc21bedeefb8274ff4f6f"
      },
      "cell_type": "code",
      "source": "### Count of both classes\nlabel_df.pivot_table(index=\"invasive\", aggfunc=len).sort_values('name', ascending=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ede2b33d8631176c00c91e2863d625a662c086f"
      },
      "cell_type": "code",
      "source": "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\ndata = ImageClassifierData.from_csv(PATH, 'train', f'{PATH}/train_labels.csv', test_name='test', # we need to specify where the test set is if you want to submit to Kaggle competitions\n                                   val_idxs=val_idxs, suffix='.jpg', tfms=tfms, bs=bs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eb1d92a19a6bc6524d3fd3688b63c18d073db84b"
      },
      "cell_type": "code",
      "source": "fn = f'{PATH}/train' + data.trn_ds.fnames[0]\n#img = PIL.Image.open(fn)\nsize_d = {k: PIL.Image.open(f'{PATH}/' + k).size for k in data.trn_ds.fnames}\nrow_sz, col_sz = list(zip(*size_d.values()))\nrow_sz = np.array(row_sz); col_sz = np.array(col_sz)\nplt.hist(row_sz);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c2a18f8275159a038e7c3ba4b77cdf282c17ef82"
      },
      "cell_type": "markdown",
      "source": "**Our first model**\nTo make the process quick we will first run a *pretrained* model and observe the results. Further, we can tweak the model for improvements. This means for our pre-trained model, that is, a model created by some one else to solve a different problem, the weights corresponding to the activation function are saved/trained and being applied here. \nThe chosen architechture to start: **resnet34** "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "64167f631c5a1bed7b75e2eb829a911b70076e00"
      },
      "cell_type": "code",
      "source": "## Data Sizes\nlen(data.trn_ds), len(data.test_ds)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e0af23db14a89412768084e24af9269e73e6056d"
      },
      "cell_type": "code",
      "source": "def get_data(sz, bs): # sz: image size, bs: batch size\n    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n    data = ImageClassifierData.from_csv(PATH, 'train', f'{PATH}/train_labels.csv', test_name='test',\n                                       val_idxs=val_idxs, suffix='.jpg', tfms=tfms, bs=bs)\n    \n    return data #if sz > 500 else data.resize(512,TMP_PATH) \n# Reading the jpgs and resizing is slow for big images, so resizing them all to 340 first saves time",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "413b3dc8869b3f0b6c65f9277bf688567544c1cc"
      },
      "cell_type": "code",
      "source": "data = get_data(sz, bs)\nlearn = ConvLearner.pretrained(arch, data, precompute=True,tmp_name=TMP_PATH, models_name=MODEL_PATH)\nlearn.fit(1e-2, 3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b89f37eb16ab38afef7c23e219e455dbcd127b9"
      },
      "cell_type": "markdown",
      "source": "Current level of Accuracy: Approx around 93-95. Now, let's try to understand what is happening by evaluation of performance metrics and looking at the right/wrong predictions. That is, we will explore:\n* A few correct labels at random\n* A few incorrect labels at random\n* The most correct labels of each class (i.e. those with highest probability that are correct)\n* The most incorrect labels of each class (i.e. those with highest probability that are incorrect)\n* The most uncertain labels (i.e. those with probability closest to 0.5)."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "058b82f460a6519c5af1873afc2142f3f05c0c39"
      },
      "cell_type": "code",
      "source": "# this gives prediction for validation set. Predictions are in log scale\nlog_preds = learn.predict()\nlog_preds.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "614738a26d521bfb61914a774679b2f65247d036",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "preds = np.argmax(log_preds, axis=1)  # from log probabilities to 0 or 1\nprobs = np.exp(log_preds[:,1])        # pr(1) # Where Species = Invasive is class 1\ndata.classes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "929f09c30a3e279bdc43e3854855fde2adcbd8d7"
      },
      "cell_type": "code",
      "source": "def rand_by_mask(mask): return np.random.choice(np.where(mask)[0], min(len(preds), 4), replace=False)\ndef rand_by_correct(is_correct): return rand_by_mask((preds == data.val_y)==is_correct)\ndef plots(ims, figsize=(12,6), rows=1, titles=None):\n    f = plt.figure(figsize=figsize)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n        sp.axis('Off')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i])\ndef load_img_id(ds, idx): return np.array(PIL.Image.open(f'{PATH}/'+ds.fnames[idx]))\n\ndef plot_val_with_title(idxs, title):\n    imgs = [load_img_id(data.val_ds,x) for x in idxs]\n    title_probs = [probs[x] for x in idxs]\n    print(title)\n    return plots(imgs, rows=1, titles=title_probs, figsize=(16,8)) if len(imgs)>0 else print('Not Found.')\n\ndef most_by_mask(mask, mult):\n    idxs = np.where(mask)[0]\n    return idxs[np.argsort(mult * probs[idxs])[:4]]\n\ndef most_by_correct(y, is_correct): \n    mult = -1 if (y==1)==is_correct else 1\n    return most_by_mask(((preds == data.val_y)==is_correct) & (data.val_y == y), mult)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad2514d044a7e816ba346db0d9025c1398125d0e"
      },
      "cell_type": "code",
      "source": "# 1. A few correct labels at random\nplot_val_with_title(rand_by_correct(True), \"Correctly classified\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c49e113c6b7dd06bb15851aaa97a772d6ea5a48d"
      },
      "cell_type": "code",
      "source": "# 2. A few incorrect labels at random\nplot_val_with_title(rand_by_correct(False), \"Incorrectly classified\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c7850a98fa36fb5d4683ca7de4562ebe67f52dfa"
      },
      "cell_type": "code",
      "source": "plot_val_with_title(most_by_correct(0, True), \"Most correct classifications: Class 0\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "19ab0ded9deed806388c626bfad510acec4c4098"
      },
      "cell_type": "code",
      "source": "plot_val_with_title(most_by_correct(1, True), \"Most correct classifications: Class 1\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f36d4e51b7d68600ef3937a136cc3a98f1b158c2"
      },
      "cell_type": "code",
      "source": "plot_val_with_title(most_by_correct(0, False), \"Most incorrect classifications: Actual Class 0 Predicted Class 1\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9cb5e193bef848f1eb4323f2cb5d51e1ba923da"
      },
      "cell_type": "code",
      "source": "plot_val_with_title(most_by_correct(1, False), \"Most incorrect classifications: Actual Class 1 Predicted Class 0\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a8f31e3a800bbf7c7c0ff3cf3f80f80442898418"
      },
      "cell_type": "code",
      "source": "most_uncertain = np.argsort(np.abs(probs -0.5))[:4]\nplot_val_with_title(most_uncertain, \"Most uncertain predictions\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2e31197ea58810f7b1c1c22d7bd17a77e2922314"
      },
      "cell_type": "markdown",
      "source": "Scope of Improvement:\n* Find an Optimal Learning Rate\n* Use Data Augmentation techniques\n* Instead of using a Pretrained model, train the layers of the neural network based on our dataset"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e780bde411f805b9ea2c549030ddfad000f7ca9a"
      },
      "cell_type": "code",
      "source": "## How does loss change with changes in Learning Rate (For the Last Layer)\nlearn.lr_find()\nlearn.sched.plot_lr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3efabcf29729098779954e7e62beab7f57d05e63"
      },
      "cell_type": "code",
      "source": "# Note that the loss is still clearly improves till lr=1e-2 (0.01). \n# The LR can vary as a part of the stochastic gradient descent over time.\nlearn.sched.plot()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0f64ef23c68d8f819443b17bd4dbdd61ae734e1b"
      },
      "cell_type": "markdown",
      "source": "**Data Augmentation**\nData augmentation is a good step to prevent overfitting. That is, by cropping/zooming/rotating the image, we can ensure that the model does not learn patterns specific to the train data and generalizes well to new data. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c2b401f22c1e4eedd356a50cd7288ce9c160af3"
      },
      "cell_type": "code",
      "source": "def get_augs():\n    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n    data = ImageClassifierData.from_csv(PATH, 'train', f'{PATH}/train_labels.csv',\n                                        bs = 2, tfms=tfms,\n                    suffix='.jpg', val_idxs=val_idxs, test_name='test')\n    x,_ = next(iter(data.aug_dl))\n    return data.trn_ds.denorm(x)[1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4b6cd4f48e8ebe6e8e66f32f7e82a3b9cb10e34"
      },
      "cell_type": "code",
      "source": "# An Example of data augmentation\nims = np.stack([get_augs() for i in range(6)])\nplots(ims, rows=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34599f5733cecf95215896366298476d6cfc5a48"
      },
      "cell_type": "code",
      "source": "#tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.2)\ndata = ImageClassifierData.from_csv(PATH,'train', f'{PATH}/train_labels.csv', tfms=tfms,\n                                      suffix='.jpg', val_idxs=val_idxs, test_name='test')\nlearn = ConvLearner.pretrained(arch, data, precompute=True,tmp_name=TMP_PATH, models_name=MODEL_PATH)\nlearn.fit(1e-2, 3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b5ddf028ca91b327a809b183b6eca1bb68afc80e"
      },
      "cell_type": "markdown",
      "source": "With Precompute = TRUE, all layers of the Neural network are set to frozen excluding the last layer. Thus we are only updating the weights in the last layer with our dataset. Now, we will train the model with the option precompute as false and cycle_len enabled. Cycle Length uses a technique called stochastic gradient descent with restarts (SGDR), a variant of learning rate annealing, which gradually decreases the learning rate as training progresses. This is helpful because as we get closer to the optimal weights, we want to take smaller steps."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ec55f4dd5579c17629d606e1023860dbf98b7749"
      },
      "cell_type": "code",
      "source": "learn.precompute=False\nlearn.fit(1e-2, 3, cycle_len=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c3373bd61d0fffd751cc42af83019eb42c00bbc"
      },
      "cell_type": "code",
      "source": "learn.sched.plot_lr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5a9f999ffdf903c0a091cce7f330b4b39b01414d"
      },
      "cell_type": "markdown",
      "source": "To unfreeze all layers however, we will call unfreeze. We will also try differential rates for the respective layers."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e229af6343551c323234a960c2588c82cd83ac47"
      },
      "cell_type": "code",
      "source": "learn.unfreeze()\nlr=np.array([1e-4,1e-3,1e-2])\nlearn.fit(lr, 3, cycle_len=1, cycle_mult=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85b8004bf55e9bc973253773be804167c8b943d3"
      },
      "cell_type": "code",
      "source": "learn.sched.plot_lr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0e452d54865e2dd15ab9b22304f012ec069f90d4"
      },
      "cell_type": "markdown",
      "source": "Above, we have the learning rate of the final layers. The learning rates of the earlier layers are fixed at the same multiples of the final layer rates as we initially requested (i.e. the first layers have 100x smaller, and middle layers 10x smaller learning rates, since we set lr=np.array([1e-4,1e-3,1e-2])."
    },
    {
      "metadata": {
        "_uuid": "df46b2c005360a284e026f9608270784b7f51be1"
      },
      "cell_type": "markdown",
      "source": "To get a better picture, we can use Test time augmentation, that is we use data augmentation techniques on our validation set. Thus, by making predictions on both the validation set images and their augmented images, we will be more accurate."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c1d7f48e0a0ec613a594246caa5a1736e777b5f3",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "log_preds,y = learn.TTA()\nprobs = np.mean(np.exp(log_preds),0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "edfcc68bbf18d6b579c865dca65c2bcafad43bcd"
      },
      "cell_type": "code",
      "source": "accuracy_np(probs, y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4544054fe62df07b45cd658d85f8f443a0f2d380"
      },
      "cell_type": "markdown",
      "source": "**Results:**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "adad988415e55088036a4617dd0a9b4a2b93dbb3"
      },
      "cell_type": "code",
      "source": "log_preds = learn.predict()\npreds = np.argmax(log_preds, axis=1)  # from log probabilities to 0 or 1\nprobs = np.exp(log_preds[:,1])        # pr(1) # Where Species = Invasive is class 1\n# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y, preds)\nplot_confusion_matrix(cm, data.classes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84c852d433022d30f4a2d211dc4760e242a66281"
      },
      "cell_type": "code",
      "source": "plot_val_with_title(most_by_correct(0, False), \"Most incorrect classifications: Actual Class 0 Predicted Class 1\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "facb00dbb777df0eac8b203f59a08cff8c210948",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "plot_val_with_title(most_by_correct(1, False), \"Most incorrect Classifications: Actual Class 1 Predicted Class 0\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "169ca89fc2d9970a4f1f6b3d882736afbafee46f"
      },
      "cell_type": "markdown",
      "source": "**Code Summary and Explanation**\n**Steps**\n*Data Exploration: *\n*     Explore the data size and get an idea of how the images look like.\n*     Check the distribution of image sizes. Resizing of Images (Standardizing) might be required to speed up the process.\n\n*Models Tweaking:*\n*      Run a quick model (smaller number of epochs) with precompute = TRUE, that is only updating the weights of last layer. \n*      Evaluate the Performance by observing the train and validation loss and the overall accuracy.\n*      Explore the Images of the most correct/incorrect classifications to understand if there are any visible patterns/reasons of wrong classification. It helps to get more comfortable with what the model is doing. \n*      Find optimal Learning Rate using lr_find(). We want a learning rate where loss is improving.\n*      Train last layer from precomputed activations for 1-2 epochs.\n*      Use data augmentation and train the last layer again (cycle_len = 1).\n*      Unfreeze all layers and retrain the model. Set the earlier layers to 3x-10x lower learning rate than next higher layer.\n*      Recheck the Learning Rate (lr_find).\n*      Train full network with cycle_mult=2 until over-fitting.\n*      Use Test time augmentation to get a better picture regarding the accuracy."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6fa2e12fa276235c0113efeecffd54ed6304c63f",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "log_preds, y = learn.TTA(is_test=True) # use test dataset rather than validation dataset\nprobs = np.mean(np.exp(log_preds),0)\ndf = pd.DataFrame(probs)\ndf.columns = data.classes\ndf = pd.DataFrame(df.loc[:, '1'])\ndf.insert(0, 'id', [o[5:-4] for o in data.test_ds.fnames])\ndf['temp'] = df['id'].astype(float)\ndf = df.sort_values('temp',ascending=True) \ndf = df.loc[:,['id','1']]\ndf.columns = ['name','invasive']\ndf.to_csv(\"submit.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}